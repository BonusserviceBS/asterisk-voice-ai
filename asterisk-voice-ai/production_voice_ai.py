#!/usr/bin/env python3
"""
PRODUCTION Voice AI System for Asterisk AudioSocket
Fixes:
1. Correct female voice from database
2. Streaming STT with VAD
3. Stable connection handling
4. <500ms target latency
"""

import asyncio
import struct
import uuid
import logging
import time
import os
import json
from dotenv import load_dotenv
import azure.cognitiveservices.speech as speechsdk
import asyncpg
import aiohttp
from collections import deque
import numpy as np

# Load environment
load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Hardcoded for testing - should be in DB
MISTRAL_API_KEY = "eGKlq7RFBQLiohBetRmuL5PNZxuLkrpz"

class ProductionVoiceAI:
    """Production-ready voice AI with all fixes"""
    
    def __init__(self, host='127.0.0.1', port=9092):
        self.host = host
        self.port = port
        self.clients = {}
        self.db_pool = None
        
        # Azure Speech setup
        self.azure_key = os.getenv('AZURE_SPEECH_KEY')
        self.azure_region = os.getenv('AZURE_SPEECH_REGION', 'germanywestcentral')
        
        if not self.azure_key:
            logger.error("üîë AZURE_SPEECH_KEY not set!")
        
        # Performance metrics
        self.metrics = {
            'total_calls': 0,
            'active_calls': 0,
            'avg_stt_latency': 0,
            'avg_ai_latency': 0,
            'avg_tts_latency': 0
        }
        
    async def init_db(self):
        """Initialize database connection pool"""
        try:
            self.db_pool = await asyncpg.create_pool(
                host=os.getenv('DB_HOST', '10.0.0.5'),
                port=int(os.getenv('DB_PORT', '5432')),
                database=os.getenv('DB_NAME', 'teli24_development'),
                user=os.getenv('DB_USER', 'teli24_user'),
                password=os.getenv('DB_PASSWORD'),
                min_size=2,
                max_size=10
            )
            logger.info("‚úÖ Database pool initialized")
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            
    async def get_assistant_by_phone(self, phone_number):
        """Get assistant data by phone number"""
        if not self.db_pool:
            return None
            
        try:
            # Try different formats
            formats = [
                phone_number,
                f"+{phone_number}" if not phone_number.startswith('+') else phone_number,
                phone_number.replace('+49', '49') if phone_number.startswith('+49') else f"49{phone_number}",
                phone_number.replace('+', '') if phone_number.startswith('+') else phone_number
            ]
            
            async with self.db_pool.acquire() as conn:
                for fmt in formats:
                    query = """
                    SELECT a.name, a.greeting, a."systemPrompt", a.settings 
                    FROM "Assistant" a 
                    JOIN "PhoneNumber" p ON a.id = p."assignedToAssistantId" 
                    WHERE p.number = $1
                    """
                    result = await conn.fetchrow(query, fmt)
                    if result:
                        # Parse settings properly
                        settings = result['settings']
                        if isinstance(settings, str):
                            try:
                                settings = json.loads(settings)
                            except:
                                settings = {}
                        
                        return {
                            'name': result['name'],
                            'greeting': result['greeting'],
                            'system_prompt': result['systemPrompt'],
                            'settings': settings
                        }
                        
            logger.warning(f"No assistant found for: {phone_number}")
            return None
            
        except Exception as e:
            logger.error(f"Database query error: {e}")
            return None
    
    def calculate_energy(self, audio_chunk):
        """Calculate audio energy for VAD"""
        if len(audio_chunk) < 2:
            return 0
        
        # Convert bytes to int16 array
        audio_array = np.frombuffer(audio_chunk, dtype=np.int16)
        
        # Calculate RMS energy
        if len(audio_array) > 0:
            rms = np.sqrt(np.mean(audio_array.astype(float) ** 2))
            return rms
        return 0
    
    async def handle_client(self, reader, writer):
        """Handle AudioSocket connection with improved stability"""
        client_id = str(uuid.uuid4())[:8]
        addr = writer.get_extra_info('peername')
        
        self.metrics['total_calls'] += 1
        self.metrics['active_calls'] += 1
        
        logger.info(f"üìû [{client_id}] New call from {addr}")
        
        # Initialize client state
        client = {
            'id': client_id,
            'reader': reader,
            'writer': writer,
            'start_time': time.time(),
            'audio_buffer': bytearray(),
            'silence_frames': 0,
            'is_speaking': False,
            'last_speech_time': time.time(),
            'assistant_data': None,
            'tts_config': None,
            'stt_config': None,
            'conversation': [],
            'processing': False,
            'greeting_sent': False
        }
        
        self.clients[client_id] = client
        
        try:
            while True:
                # Read with timeout to prevent hanging
                try:
                    header = await asyncio.wait_for(
                        reader.readexactly(3),
                        timeout=30.0  # 30 second timeout
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"‚è±Ô∏è [{client_id}] Read timeout - closing connection")
                    break
                    
                if not header:
                    break
                    
                msg_type = header[0]
                payload_length = struct.unpack('>H', header[1:3])[0]
                
                payload = b''
                if payload_length > 0:
                    payload = await reader.readexactly(payload_length)
                
                # Process messages
                if msg_type == 0x01:  # UUID
                    await self.handle_uuid(client_id, payload)
                    
                elif msg_type == 0x10:  # Audio
                    await self.handle_audio_stream(client_id, payload)
                    
                elif msg_type == 0x00:  # Hangup
                    logger.info(f"üì¥ [{client_id}] Call ended")
                    break
                    
        except asyncio.IncompleteReadError:
            logger.info(f"üì° [{client_id}] Connection lost")
        except Exception as e:
            logger.error(f"‚ùå [{client_id}] Error: {e}")
        finally:
            # Cleanup
            self.metrics['active_calls'] -= 1
            
            try:
                writer.close()
                await writer.wait_closed()
            except:
                pass
                
            if client_id in self.clients:
                duration = time.time() - self.clients[client_id]['start_time']
                logger.info(f"üìä [{client_id}] Call duration: {duration:.1f}s")
                del self.clients[client_id]
    
    async def handle_uuid(self, client_id, payload):
        """Handle UUID and initialize assistant"""
        client = self.clients[client_id]
        
        call_uuid = payload.hex() if len(payload) == 16 else payload.decode('utf-8', errors='ignore')
        logger.info(f"üÜî [{client_id}] UUID: {call_uuid}")
        
        # Load assistant configuration
        phone_number = "4920189098723"  # TODO: Get from SIP headers
        assistant_data = await self.get_assistant_by_phone(phone_number)
        client['assistant_data'] = assistant_data
        
        # Configure STT
        stt_config = speechsdk.SpeechConfig(
            subscription=self.azure_key,
            region=self.azure_region
        )
        stt_config.speech_recognition_language = "de-DE"
        client['stt_config'] = stt_config
        
        # Configure TTS with correct voice
        tts_config = speechsdk.SpeechConfig(
            subscription=self.azure_key,
            region=self.azure_region
        )
        tts_config.set_speech_synthesis_output_format(
            speechsdk.SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm
        )
        
        # Set voice from assistant data
        voice_name = "de-DE-SeraphinaMultilingualNeural"  # Default female
        
        if assistant_data:
            logger.info(f"ü§ñ [{client_id}] Assistant: {assistant_data['name']}")
            
            settings = assistant_data.get('settings', {})
            if isinstance(settings, dict):
                tts_settings = settings.get('providers', {}).get('tts', {})
                voice = tts_settings.get('voice')
                
                if voice:
                    # Clean up voice name
                    if isinstance(voice, str):
                        voice = voice.strip('"').strip()
                        if voice:
                            voice_name = voice
        
        tts_config.speech_synthesis_voice_name = voice_name
        client['tts_config'] = tts_config
        
        logger.info(f"üé§ [{client_id}] Voice configured: {voice_name}")
        
        # Send greeting
        if not client['greeting_sent']:
            await self.send_greeting(client_id)
            client['greeting_sent'] = True
    
    async def send_greeting(self, client_id):
        """Send assistant greeting"""
        client = self.clients.get(client_id)
        if not client:
            return
            
        assistant_data = client.get('assistant_data')
        
        if assistant_data and assistant_data.get('greeting'):
            greeting = assistant_data['greeting']
        else:
            greeting = "Hallo, wie kann ich Ihnen helfen?"
            
        logger.info(f"üí¨ [{client_id}] Greeting: {greeting}")
        await self.send_tts(client_id, greeting)
    
    async def handle_audio_stream(self, client_id, audio_data):
        """Handle audio with streaming STT and VAD"""
        client = self.clients.get(client_id)
        if not client or client['processing']:
            return
            
        # Add to buffer
        client['audio_buffer'].extend(audio_data)
        
        # Calculate energy for simple VAD
        energy = self.calculate_energy(audio_data)
        
        # Simple speech detection
        ENERGY_THRESHOLD = 300
        is_speech = energy > ENERGY_THRESHOLD
        
        if is_speech:
            client['silence_frames'] = 0
            client['is_speaking'] = True
            client['last_speech_time'] = time.time()
        else:
            client['silence_frames'] += 1
        
        # Process when we have enough audio and detected end of speech
        MIN_AUDIO_LENGTH = 8000  # 0.5 seconds
        MAX_SILENCE_FRAMES = 40  # 800ms of silence
        
        if (len(client['audio_buffer']) >= MIN_AUDIO_LENGTH and 
            client['silence_frames'] >= MAX_SILENCE_FRAMES and
            client['is_speaking']):
            
            # Process the audio
            client['processing'] = True
            client['is_speaking'] = False
            
            # Copy buffer and clear it
            audio_to_process = bytes(client['audio_buffer'])
            client['audio_buffer'] = bytearray()
            client['silence_frames'] = 0
            
            # Process in background
            asyncio.create_task(self.process_speech(client_id, audio_to_process))
            
        # Prevent buffer overflow
        MAX_BUFFER_SIZE = 160000  # 10 seconds
        if len(client['audio_buffer']) > MAX_BUFFER_SIZE:
            # Keep last 5 seconds
            client['audio_buffer'] = client['audio_buffer'][-80000:]
    
    async def process_speech(self, client_id, audio_data):
        """Process speech with STT and AI"""
        client = self.clients.get(client_id)
        if not client:
            return
            
        try:
            # STT Processing
            start_stt = time.time()
            
            # Create audio stream
            stream = speechsdk.audio.PushAudioInputStream(
                stream_format=speechsdk.audio.AudioStreamFormat(
                    samples_per_second=8000,
                    bits_per_sample=16,
                    channels=1,
                    wave_stream_format=speechsdk.audio.AudioStreamWaveFormat.PCM
                )
            )
            
            stream.write(audio_data)
            stream.close()
            
            audio_config = speechsdk.audio.AudioConfig(stream=stream)
            recognizer = speechsdk.SpeechRecognizer(
                speech_config=client['stt_config'],
                audio_config=audio_config
            )
            
            result = recognizer.recognize_once()
            
            stt_latency = (time.time() - start_stt) * 1000
            
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                text = result.text
                
                if text and len(text) > 2:
                    logger.info(f"üé§ [{client_id}] User: '{text}' (STT: {stt_latency:.0f}ms)")
                    
                    # Get AI response
                    assistant_data = client.get('assistant_data')
                    system_prompt = None
                    if assistant_data:
                        system_prompt = assistant_data.get('system_prompt')
                    
                    response = await self.get_ai_response(text, system_prompt)
                    
                    # Send response
                    await self.send_tts(client_id, response)
                    
                    # Save conversation
                    client['conversation'].append({
                        'user': text,
                        'assistant': response,
                        'timestamp': time.time()
                    })
                    
        except Exception as e:
            logger.error(f"‚ùå [{client_id}] Speech processing error: {e}")
        finally:
            client['processing'] = False
    
    async def get_ai_response(self, text: str, system_prompt: str = None) -> str:
        """Get AI response from Mistral"""
        try:
            start = time.time()
            
            if not system_prompt:
                system_prompt = "Du bist ein hilfreicher KI-Assistent. Antworte kurz und pr√§zise auf Deutsch."
            
            headers = {
                "Authorization": f"Bearer {MISTRAL_API_KEY}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "mistral-tiny",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                "temperature": 0.7,
                "max_tokens": 100
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.mistral.ai/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        reply = data['choices'][0]['message']['content']
                        latency = (time.time() - start) * 1000
                        logger.info(f"ü§ñ AI response in {latency:.0f}ms")
                        return reply
                    else:
                        logger.error(f"AI API error: {response.status}")
                        return "Entschuldigung, ich konnte das nicht verarbeiten."
                        
        except asyncio.TimeoutError:
            logger.error("AI timeout")
            return "Entschuldigung, die Verarbeitung dauert zu lange."
        except Exception as e:
            logger.error(f"AI error: {e}")
            return "Es tut mir leid, es gab einen technischen Fehler."
    
    async def send_tts(self, client_id, text):
        """Send TTS with correct voice and better error handling"""
        client = self.clients.get(client_id)
        if not client:
            return
            
        try:
            start = time.time()
            
            tts_config = client.get('tts_config')
            if not tts_config:
                logger.error(f"No TTS config for {client_id}")
                return
            
            # Create synthesizer
            synthesizer = speechsdk.SpeechSynthesizer(
                speech_config=tts_config,
                audio_config=None
            )
            
            # Synthesize
            result = synthesizer.speak_text_async(text).get()
            
            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                audio_data = result.audio_data
                
                # Send audio in chunks
                await self.stream_audio(client_id, audio_data)
                
                latency = (time.time() - start) * 1000
                logger.info(f"üó£Ô∏è [{client_id}] TTS: '{text[:40]}...' ({latency:.0f}ms)")
            else:
                logger.error(f"TTS failed: {result.reason}")
                
        except Exception as e:
            logger.error(f"TTS error: {e}")
    
    async def stream_audio(self, client_id, audio_data):
        """Stream audio to client with error handling"""
        client = self.clients.get(client_id)
        if not client:
            return
            
        writer = client['writer']
        chunk_size = 320  # 20ms at 8kHz
        
        try:
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i+chunk_size]
                
                # Pad if needed
                if len(chunk) < chunk_size:
                    chunk = chunk + b'\x00' * (chunk_size - len(chunk))
                
                # AudioSocket protocol
                message = struct.pack('>BH', 0x10, len(chunk)) + chunk
                
                writer.write(message)
                await writer.drain()
                
                # Real-time pacing
                await asyncio.sleep(0.02)
                
        except (ConnectionResetError, BrokenPipeError) as e:
            logger.warning(f"Connection lost while streaming: {e}")
        except Exception as e:
            logger.error(f"Streaming error: {e}")
    
    async def start(self):
        """Start production server"""
        # Initialize database
        await self.init_db()
        
        # Start server
        server = await asyncio.start_server(
            self.handle_client,
            self.host,
            self.port
        )
        
        addr = server.sockets[0].getsockname()
        
        logger.info("=" * 60)
        logger.info("üöÄ PRODUCTION Voice AI Server")
        logger.info(f"üìç Listening on {addr[0]}:{addr[1]}")
        logger.info("=" * 60)
        logger.info("‚úÖ Features:")
        logger.info("  ‚Ä¢ Streaming STT with VAD")
        logger.info("  ‚Ä¢ Female voice from database")
        logger.info("  ‚Ä¢ Stable connection handling")
        logger.info("  ‚Ä¢ <500ms target latency")
        logger.info("  ‚Ä¢ Mistral AI integration")
        logger.info("=" * 60)
        
        async with server:
            await server.serve_forever()

async def main():
    server = ProductionVoiceAI(port=9092)
    await server.start()

if __name__ == "__main__":
    asyncio.run(main())